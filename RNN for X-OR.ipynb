{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network on X-OR gate, this temporal/sequential based challenge is as presented in Jeff Heaton youtube channel (  https://www.youtube.com/watch?v=e2sGq_vI41s  ). At timestamp 3:50 shows the advantage of using temporal/sequential methods such as RNN.\n",
    "\n",
    "#### 0 \t0 |\t0\n",
    "#### 0 \t1 |\t1\n",
    "#### 1 \t0 |\t1\n",
    "#### 1 \t1 |\t0\n",
    "\n",
    "### Reshape to X-OR to temporal/sequential challenge\n",
    "\n",
    "#### now | later\n",
    "#### 0      | 0\n",
    "#### 0      | 0\n",
    "#### 0      | 0\n",
    "#### 0      | 1\n",
    "#### 1      | 1\n",
    "#### 1      | 1\n",
    "#### 1      | 0\n",
    "#### 0      | 1\n",
    "#### 1      | 1\n",
    "#### 1      | 1\n",
    "#### 1      | 0\n",
    "\n",
    "\n",
    "##### .shazri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:[ 0.68636508]\n",
      "Error:[ 0.01090575]\n",
      "Error:[ 0.00765828]\n",
      "Error:[ 0.00623417]\n",
      "Error:[ 0.00538938]\n",
      "Error:[ 0.00481462]\n",
      "Error:[ 0.00439125]\n",
      "Error:[ 0.00406273]\n",
      "Error:[ 0.00379825]\n",
      "Error:[ 0.0035794]\n",
      "Error:[ 0.00339441]\n",
      "Error:[ 0.00323538]\n",
      "Error:[ 0.00309676]\n",
      "Error:[ 0.00297452]\n",
      "Error:[ 0.00286567]\n",
      "Error:[ 0.00276795]\n",
      "Error:[ 0.00267956]\n",
      "Error:[ 0.00259913]\n",
      "Error:[ 0.00252552]\n",
      "Error:[ 0.00245782]\n",
      "Error:[ 0.00239527]\n",
      "Error:[ 0.00233727]\n",
      "Error:[ 0.00228328]\n",
      "Error:[ 0.00223286]\n",
      "Error:[ 0.00218564]\n",
      "Error:[ 0.00214128]\n",
      "Error:[ 0.00209952]\n",
      "Error:[ 0.00206011]\n",
      "Error:[ 0.00202283]\n",
      "Error:[ 0.00198751]\n"
     ]
    }
   ],
   "source": [
    "import copy, numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# transfer function\n",
    "def TransferF(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "# derivative transfer function\n",
    "def TransferFPrime(output):\n",
    "    return output*(1-output)\n",
    "\n",
    "\n",
    "\n",
    "int2binary = {}\n",
    "binary_dim = 1\n",
    "\n",
    "largest_number = pow(2,binary_dim)\n",
    "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
    "for i in range(largest_number):\n",
    "    int2binary[i] = binary[i]\n",
    "\n",
    "\n",
    "alpha = 0.1\n",
    "input_dim = 1\n",
    "hidden_dim = 16\n",
    "output_dim = 1\n",
    "\n",
    "\n",
    "# initialize neural network weights\n",
    "synapse_0 = 2*np.random.random((input_dim,hidden_dim)) - 1\n",
    "synapse_1 = 2*np.random.random((hidden_dim,output_dim)) - 1\n",
    "synapse_h = 2*np.random.random((hidden_dim,hidden_dim)) - 1\n",
    "\n",
    "synapse_0_update = np.zeros_like(synapse_0)\n",
    "synapse_1_update = np.zeros_like(synapse_1)\n",
    "synapse_h_update = np.zeros_like(synapse_h)\n",
    "\n",
    "# training logic\n",
    "for j in range(30000):\n",
    "    \n",
    "    for k in range(11):\n",
    "        \n",
    "        if k==0:\n",
    "            now_int = 0\n",
    "            now= int2binary[now_int] \n",
    "\n",
    "            \n",
    "            later_int = 0\n",
    "            later= int2binary[later_int]\n",
    "        if k==1:\n",
    "            now_int = 0\n",
    "            now= int2binary[now_int] \n",
    "\n",
    "           \n",
    "            later_int = 0\n",
    "            later= int2binary[later_int]\n",
    "        if k==2:\n",
    "            now_int = 0\n",
    "            now= int2binary[now_int] \n",
    "            \n",
    "            \n",
    "            later_int = 0\n",
    "            later= int2binary[later_int]\n",
    "        if k==3:\n",
    "            now_int = 0\n",
    "            now= int2binary[now_int] \n",
    "\n",
    "            \n",
    "            later_int = 1\n",
    "            later= int2binary[later_int]\n",
    "        if k==4:\n",
    "            now_int = 1\n",
    "            now= int2binary[now_int] \n",
    "\n",
    "            \n",
    "            later_int = 1\n",
    "            later= int2binary[later_int]\n",
    "        if k==5:\n",
    "            now_int = 1\n",
    "            now= int2binary[now_int] \n",
    "\n",
    "            \n",
    "            later_int = 1\n",
    "            later= int2binary[later_int]\n",
    "        if k==6:\n",
    "            now_int = 1\n",
    "            now= int2binary[now_int] \n",
    "\n",
    "            \n",
    "            later_int = 0\n",
    "            later= int2binary[later_int]\n",
    "        if k==7:\n",
    "            now_int = 0\n",
    "            now= int2binary[now_int] \n",
    "\n",
    "            \n",
    "            later_int = 1\n",
    "            later= int2binary[later_int]\n",
    "        if k==8:\n",
    "            now_int = 1\n",
    "            now= int2binary[now_int] \n",
    "\n",
    "            \n",
    "            later_int = 1\n",
    "            later= int2binary[later_int]\n",
    "        if k==9:\n",
    "            now_int = 1\n",
    "            now= int2binary[now_int] \n",
    "            \n",
    "            later_int = 1\n",
    "            later= int2binary[later_int]\n",
    "        if k==10:\n",
    "            now_int = 1\n",
    "            now= int2binary[now_int] \n",
    "            \n",
    "            later_int = 0\n",
    "            later= int2binary[later_int]\n",
    "\n",
    "        d = np.zeros_like(c)\n",
    "\n",
    "        overallError = 0\n",
    "\n",
    "        layer_2_deltas = list()\n",
    "        layer_1_values = list()\n",
    "        layer_1_values.append(np.zeros(hidden_dim))\n",
    "\n",
    "        # moving along the positions in the binary encoding\n",
    "        for position in range(binary_dim):\n",
    "\n",
    "            # generate input and output\n",
    "            X = np.array(now[binary_dim - position - 1])\n",
    "            y = np.array([[later[binary_dim - position - 1]]]).T\n",
    "\n",
    "            # hidden layer (input ~+ prev_hidden)\n",
    "            layer_1 = TransferF(np.dot(X,synapse_0) + np.dot(layer_1_values[-1],synapse_h))\n",
    "\n",
    "            # output layer (new binary representation)\n",
    "            layer_2 = TransferF(np.dot(layer_1,synapse_1))\n",
    "\n",
    "            # did we miss?... if so, by how much?\n",
    "            layer_2_error = y - layer_2\n",
    "            layer_2_deltas.append((layer_2_error)*TransferFPrime(layer_2))\n",
    "            overallError += np.abs(layer_2_error[0])\n",
    "\n",
    "            # decode estimate so we can print it out\n",
    "            d[binary_dim - position - 1] = np.round(layer_2[0][0])\n",
    "\n",
    "            # store hidden layer so we can use it in the next timestep\n",
    "            layer_1_values.append(copy.deepcopy(layer_1))\n",
    "\n",
    "        future_layer_1_delta = np.zeros(hidden_dim)\n",
    "\n",
    "        for position in range(binary_dim):\n",
    "\n",
    "            X = np.array(now[position])\n",
    "            layer_1 = layer_1_values[-position-1]\n",
    "            prev_layer_1 = layer_1_values[-position-2]\n",
    "\n",
    "            # error at output layer\n",
    "            layer_2_delta = layer_2_deltas[-position-1]\n",
    "            # error at hidden layer\n",
    "            layer_1_delta = (future_layer_1_delta.dot(synapse_h.T) + layer_2_delta.dot(synapse_1.T)) * TransferFPrime(layer_1)\n",
    "\n",
    "            # let's update all our weights so we can try again\n",
    "            synapse_1_update += np.atleast_2d(layer_1).T.dot(layer_2_delta)\n",
    "            synapse_h_update += np.atleast_2d(prev_layer_1).T.dot(layer_1_delta)\n",
    "            synapse_0_update += X.T.dot(layer_1_delta)\n",
    "\n",
    "            future_layer_1_delta = layer_1_delta\n",
    "\n",
    "\n",
    "        synapse_0 += synapse_0_update * alpha\n",
    "        synapse_1 += synapse_1_update * alpha\n",
    "        synapse_h += synapse_h_update * alpha    \n",
    "\n",
    "        synapse_0_update *= 0\n",
    "        synapse_1_update *= 0\n",
    "        synapse_h_update *= 0\n",
    "\n",
    "    \n",
    "    # print out progress\n",
    "    if(j % 1000 == 0):\n",
    "        print(\"Error:\" + str(overallError))\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
